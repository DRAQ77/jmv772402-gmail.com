{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWBRQyXtUNi4"
   },
   "source": [
    "# Objetivo posible:\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/a/ac/Skulptur_tuebingen_vulva.jpg\n",
    "\n",
    "# Estilos Posibles a transferir a las imagenes\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/4/46/Vincent_Willem_van_Gogh_127.jpg\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/7/71/Paul_Gauguin_104.jpg\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/6/6a/Vincent_van_Gogh_-_The_yellow_house_%28%60The_street%27%29_-_Google_Art_Project.jpg\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/c/ca/Vincent_van_Gogh_-_Sunflowers_%28Metropolitan_Museum_of_Art%29.jpg\n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/8/8d/Two_sunflowers.jpg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "CwJnRbaToMKf",
    "outputId": "e43a3816-46c3-4f40-b229-a10e8e0a8bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hume8hMmrqPi"
   },
   "outputs": [],
   "source": [
    "path_img = '/content/drive/My Drive/ITBA/01 - TRABAJO_FINAL/img/GOPR0154.JPG'\n",
    "path_Style = '/content/drive/My Drive/ITBA/01 - TRABAJO_FINAL/style/Two_sunflowers.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "kyHsa2t0SxZi",
    "outputId": "37fc92a1-b1ab-45fa-f11e-873c5c094264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-25 19:53:42--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 223725 (218K) [image/jpeg]\n",
      "Saving to: ‘La_noche_estrellada1.jpg’\n",
      "\n",
      "\r",
      "La_noche_estrellada   0%[                    ]       0  --.-KB/s               \r",
      "La_noche_estrellada  43%[=======>            ]  95.15K   456KB/s               \r",
      "La_noche_estrellada 100%[===================>] 218.48K   722KB/s    in 0.3s    \n",
      "\n",
      "2020-02-25 19:53:43 (722 KB/s) - ‘La_noche_estrellada1.jpg’ saved [223725/223725]\n",
      "\n",
      "--2020-02-25 19:53:44--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 153015 (149K) [image/jpeg]\n",
      "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’\n",
      "\n",
      "775px-Neckarfront_T 100%[===================>] 149.43K   593KB/s    in 0.3s    \n",
      "\n",
      "2020-02-25 19:53:45 (593 KB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’ saved [153015/153015]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para estilo\n",
    "\n",
    "# Cambios en imagen de Estilo\n",
    "# !wget https://upload.wikimedia.org/wikipedia/commons/8/8d/Two_sunflowers.jpg\n",
    "\n",
    "# Original\n",
    " !wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
    "\n",
    "# Cambios en imagen imagen de contenido\n",
    "# !wget https://upload.wikimedia.org/wikipedia/commons/a/ac/Skulptur_tuebingen_vulva.jpg\n",
    "\n",
    "# Original\n",
    " !wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
    "\n",
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "NIxH20o2eFoc",
    "outputId": "1ae0fd26-1999-47c5-84b9-e6b1c03e1163"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "# Modificacion a Contexto\n",
    "# base_image_path = Path('/content/Skulptur_tuebingen_vulva.jpg')\n",
    "\n",
    "# Original\n",
    " base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "\n",
    "# Modificacion a Estilo\n",
    "# style_reference_image_path = Path('/content/Two_sunflowers.jpg')\n",
    "\n",
    "# Original\n",
    " style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n",
    "\n",
    "\n",
    "result_prefix = Path(\"/content/output\")\n",
    "iterations = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "*Respuesta:* \n",
    "\n",
    "<font color=\"003300\"><B>\n",
    "**total_variation_weight:**</b>\n",
    "\n",
    "- Se aplica en la búsqueda de equilibrio entre la estilización de la imagen y efectos de estilo.\n",
    "\n",
    "- Permite balancear el peso que tendrá en la Loss Total la función total_variation_loss(combination_image). Logrando que el cómputo de total_variation_loss(combination_image), el cual es creciente por cada ejecución de bucle, reduzca la convergencia de la loss, este proceso tiene efecto sobre la prevalencia de las capas intermedias, haciendo que los contornos definidos por la función de contexto tiendan a desaparecer y sean exaltados los contornos propios existentes en la imagen de estilo cuando tiende a crecer. \n",
    "\n",
    "- A continuación se expone la resultante de haber valorado, para la primera imagen, la variable total_variation_weight con una alta ponderación 0.9, a su lado se presenta la segunda con tendencia a neutral a cero, es de notar como en la segunda imagen los contornos mas definidos.\n",
    "</font>\n",
    "\n",
    "\n",
    "| total_variation_weight = 0.9 | total_variation_weight = 0.1        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Res_Loss_stylw_1_contw_10_TotVar_0.9_ite_39.png\">| <img src=\"image/Res_Loss_stylw_1_contw_10_TotVar_0_iter_39.png\">\n",
    "\n",
    "<font color=\"003300\"><b>\n",
    "**style_weight**</b>\n",
    "\n",
    "- Se utiliza para definir el parámetro BETA, el cual define el peso en la Loss de la imagen de Estilo. El estilo se mide como la correlación entre diferentes activaciones del mapa de features en una capa particular. Cuando el estilo cobra peso en el balance de la ecuación de la loss, los detalles de los contornos de los objetos y los objetos de menor participación en la imagen total serán reconocidos con menor facilidad.\n",
    "</font>\n",
    "\n",
    "| style_weight = 1 | style_weight = 10        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Res_Loss_stylw_1_contw_10_ite_39.png\">| <img src=\"image/Res_Loss_stylw_10_contw_1_ite_39.png\">\n",
    "\n",
    "<font color=\"003300\"><b>\n",
    "**content_weight:**</b>\n",
    "\n",
    "-  Se utiliza para definir el parámetro ALFA, define la relevancia de la Loss para la imagen de Contexto. Las capas superiores de una CNN que ha sido entrenada con un gran conjunto de datos, como ser la (VGG19), aprende a identificar explícitamente las representaciones de objetos que estén contenidos en la imagen, la particularidad de este aprendizaje pone en evidencia que el aprendizaje de valores de pixeles no se da de esta manera, es por ello una imagen que genera una activación similar a otra en una capa superior tendrá contenido similar pero es más difícil de garantizar resultado similar en los pixels.\n",
    "</font>\n",
    "\n",
    "| content_weight = 1 | content_weight = 10        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Res_Loss_stylw_10_contw_1_ite_39.png\">| <img src=\"image/Res_Loss_stylw_1_contw_10_ite_39.png\">\n",
    "\n",
    "<font color=\"003300\">\n",
    "    \n",
    "- Los efectos más apreciables en los cambios de pesos de los ponderadores de Estilo y Contexto se hacen más visibles al observar el reflejo de las figuras sobre el agua, donde a las capas superiores comienzan a recibir clasificaciones no tan probables para determinados objetos. En los casos donde el estilo toma preponderancia por sobre el contexto, las líneas que definen el contorno de los objetos como así también los objetos que la conforman tienden a desvanecerse. A diferencia de los cambios de contorno expuestos por modificación del peso del total_variation_weight, elevar la valoración de estilo hace que la pérdida de contorno esté dada por la aparición de los contornos existentes en la imagen de estilo.\n",
    "\n",
    "- La estandarización de las imágenes (definición de tamaño) se realiza a través de la combinación de los parámetros en la celda en la que se definen los valores de img_nrows y img_ncols siendo:  width, height = load_img(base_image_path).size de donde se obtienen de la imagen de contexto los valores de ancho y alto de la imagen que aporta el contexto para la imagen final. Estos valores son aplicados en la determinación de los valores de la variables img_ncols: img_ncols=int(width*img_nrows/height), la que a su vez adopta el parámetro definido en img_nrows\n",
    "\n",
    "- Es decir que esta celda aporta los valores de ancho y alto de la imagen de Contexto para posteriormente determinar los valores de las variables img_nrows y img_nclos, las que serán utilizadas durante el proceso de convergencia de las imágenes de estilo y contexto.\n",
    "</font>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.9          # Se aplica en la búsqueda de equilibrio entre la estilización de la imagen y efectos de estilo\n",
    "style_weight = 1                      # Beta que da el peso del stilo en la loss\n",
    "content_weight = 10                   # Alfa que da el peso del contexto en la loss\n",
    "\n",
    "\n",
    "#Celda incorporada para clasificar las salidas en funcion de los parámetros elegidos\n",
    "\n",
    "NombreSalida = '_Loss_stylw_' + str(style_weight) + '_contw_' + str(content_weight) + '_TotVar_' + str(total_variation_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "                                      # Definimos el tamaño de las imágenes a utilizar / generar al aplicar las dimensiones en el tensor que incorpora combination_image\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "*Respuesta:*\n",
    "<font color=\"003300\">\n",
    "**preprocess_imege()**\n",
    "\n",
    "- La funcion  tiene por objetivo abrir, redimencionar y formatear las imagenes a formato de Tensores que permita ser interpretados por la red neuronal convolutional VGG19. Este paso se completa con la función de keras K.variable() que convierte definitivamente un numpy array en un Tensor.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))        # Cargamos la imagen e ingresamos las medidas de altura y ancho\n",
    "    img = img_to_array(img)                                               # Convierte los pixeles de la imagen a un array de numpy\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "*Respuesta:*\n",
    "<font color=\"003300\">\n",
    "    \n",
    "    \n",
    "**deprocess_image()**\n",
    "\n",
    "- Función que permite convertir un Tensor a un formato de imagen valido. Es la acción inversa de la realizada en la imagen anterior.\n",
    "- Donde [103.939, 116.779, 123.68] son las medias de los canales de BGR para el proceso de VVG\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "                                                                      # get tensor representations of our images\n",
    "                                                                      # K.variable convierte un numpy array en un tensor\n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "a1Lbw02Uu--o",
    "outputId": "dce48ffa-46ae-48e1-b419-115b859afeb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nfZuKGZ50daj",
    "outputId": "ae13825b-c30c-4d8f-aa39-c1529a029232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(1, 400, 517, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "                                                                      # k.placeholder --> incorporo la infromacion de img_rowa y img_ncols a un tensor\n",
    "                                                                      # introduce los parametros de tamaño WH and C\n",
    "\n",
    "print(combination_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "*Aclaración:*\n",
    "<font color=\"003300\"><b>\n",
    "**La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch.**\n",
    "</b></font>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "                                                                      # combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "tdG59VRavHGB",
    "outputId": "57a030dd-6e2f-459b-e75a-13dab5a86374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "                                                                      # build the VGG19 network with our 3 images as input\n",
    "                                                                      # the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "                                                                      # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "# - ¿Qué es la matriz de Gram?¿Para qué se usa? \n",
    "\n",
    "*Respuesta:*\n",
    "<font color=\"003300\">\n",
    "- La Matriz de Gram, permite comprobar la interdependencia lineal, un conjunto de vectores será linealmente interdependientes si y solo si el determinante de Gram no es nulo(la matriz de Gram es invertible). \n",
    "- Es aplicado cuando se define la loss de estilo, ya que permite la extracción de los features maps de la imagen de estilo. Dado que las relaciones en las capas inferirores es predominantemente lineal.\n",
    "- Esto último se logra al minimizar el cuadrado del error de la distancia entre la entrada de la matriz de Gram de la imagen original y la matriz de Gram de la imagen generada.\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "# Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "*Respuesta:*\n",
    "\n",
    "\n",
    "<font color=\"003300\">\n",
    "<ol>\n",
    "    <li>style_loss(): Se utiliza para mantener el estilo de la imagen de referencia en la imagen generada.  En el estilo recogemos colores y patrones, por lo que se utilizan capas inferiores que capturan características de bajo nivel.\n",
    "    </li>\n",
    "    <li>content_loss(): Tiene por objeto mantener el contenido de la imagen base. Se considera la idea de que las imágenes con similar contorno tendrán representaciones similares en las capas superiores de la red.\n",
    "    </li>\n",
    "    <li>total_variation_loss(): Busca mantener la coherencia de la imagen base. Dado que el alfa y el beta representan los pesos del estilo y el contenido, la Loss Total, resulta en la representación del problema. Necesitamos que el contexto de la imagen resultante (identificación de objetos) sea similar a los ingresados/captados desde la imagen de contexto de entrada y el estilo entonces de la imagen resultante estará aportado por la imagen ingresada de estilo (colores y patrones). \n",
    "    </li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):                                 # Mantener el estilo de la imagen de referencia en la imagen generada\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):                                # Tiene por objetivo mantener el contenido de la imagen base\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4                                           # Si K.ndim == 4 no hace nada sino // Diseñada para matener la coherencia de la imagen base\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "                                                                    # Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JkrOyKZ8DXDb",
    "outputId": "ee7f2673-91f7-42d3-f51f-ebee134412ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum_7:0\", shape=(), dtype=float32)\n",
      "Tensor(\"truediv_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_7:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(total_variation_loss(combination_image))\n",
    "print(sl)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pbz4n1OhvV2K",
    "outputId": "689c9249-09b7-4353-be76-ba33e2109446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "*Respuesta:*\n",
    "<font color=\"003300\">\n",
    "- El proposito de las celdas (def eval_loss_and_grads(x) y class Evaluator()) **eval_loss_and_grads(x)** hace posible computar la loss y el gradiente en un paso  cuando estos son recibidos como dos funciones independientes. Esto se realiza porque scipy.optimize requiere las funciones de evaluación loss y gradiente por separado, pero realizar los cálculos en esta forma resultaría ineficiente.\n",
    "\n",
    "\n",
    "- **from scipy.optimize import fmin_l_bfgs_b** La funcion fmin_l_bfgs_b minimiza la función evaluator.loss, con el gradiente evaluator.grads evaluando un máximo de 20 iteraciones.\n",
    "\n",
    "\n",
    "- Para la síntesis de la imagen (Gatys, Ecker, Bethge) reemplazaron max-pooling por average pooling lo que mejora el flujo del gradiente y por el cual se obtienen resultados aparentemente mejores.\n",
    "\n",
    "</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVE1_qemvZeN"
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3)) # la red espera una o mas imagenes como entrada\n",
    "    outs = f_outputs([x])                       # Muestras, Filas, Columnas, Canales\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# Esta funcion class Evaluator() hace posible que se compute la loss y los gradientes en un solo paso\n",
    "# mientras los recibe de dos funciones separadas. 'loss' y 'grads'.\n",
    "# Esto se hace dado que scipy.optimize requiere las funciones loss y gradientes por separado\n",
    "# y calcularlas se forma separada reduciria la performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SL3m7Q8MSdb8"
   },
   "outputs": [],
   "source": [
    "# print(x.reshape((1, img_nrows, img_ncols, 3)))       le estamos diciendo a la VGG19 que le va a ir 1 imagen\n",
    "#                                                      con esas dimenciones y 3 canales por lo colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "9ipK5b-hbuBW",
    "outputId": "3753eefe-4b92-4a4a-e716-f1ddeeaeb8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  98.061       85.221       72.32     ]\n",
      "   [ 102.061       88.221       77.32     ]\n",
      "   [ 105.061       91.221       80.32     ]\n",
      "   ...\n",
      "   [  34.060997    11.221001    -2.6800003]\n",
      "   [  33.060997    10.221001    -3.6800003]\n",
      "   [  32.060997     9.221001    -4.6800003]]\n",
      "\n",
      "  [[  93.061       77.221       65.32     ]\n",
      "   [  96.061       80.221       68.32     ]\n",
      "   [  99.061       83.221       72.32     ]\n",
      "   ...\n",
      "   [  31.060997     8.221001    -5.6800003]\n",
      "   [  30.060997     7.2210007   -6.6800003]\n",
      "   [  28.060997     5.2210007   -8.68     ]]\n",
      "\n",
      "  [[  93.061       77.221       65.32     ]\n",
      "   [  96.061       80.221       68.32     ]\n",
      "   [  98.061       82.221       70.32     ]\n",
      "   ...\n",
      "   [  31.060997     8.221001    -5.6800003]\n",
      "   [  30.060997     7.2210007   -6.6800003]\n",
      "   [  29.060997     6.2210007   -7.6800003]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  25.060997    35.221        6.3199997]\n",
      "   [-103.939     -102.779     -123.68     ]\n",
      "   [ -94.939      -90.779     -108.68     ]\n",
      "   ...\n",
      "   [ -99.939      -49.779      -58.68     ]\n",
      "   [-102.939      -52.779      -61.68     ]\n",
      "   [ -92.939      -42.779      -51.68     ]]\n",
      "\n",
      "  [[-101.939     -103.779     -123.68     ]\n",
      "   [-103.939     -111.779     -123.68     ]\n",
      "   [-100.939     -105.779     -119.68     ]\n",
      "   ...\n",
      "   [-100.939      -49.779      -61.68     ]\n",
      "   [-101.939      -50.779      -62.68     ]\n",
      "   [ -94.939      -44.779      -53.68     ]]\n",
      "\n",
      "  [[ -27.939003   -42.779      -59.68     ]\n",
      "   [ -96.939     -112.779     -123.68     ]\n",
      "   [ -99.939     -116.779     -123.68     ]\n",
      "   ...\n",
      "   [ -92.939      -41.779      -53.68     ]\n",
      "   [ -90.939      -39.779      -51.68     ]\n",
      "   [-101.939      -50.779      -62.68     ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_image(base_image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n31YBwCVvhAI",
    "outputId": "9c196e03-33d9-44cf-aecb-122eff432238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 7002775600.0\n",
      "Image saved as /content/output/output_at_iteration_0.png\n",
      "Iteration 0 completed in 6s\n",
      "Start of iteration 1\n",
      "Current loss value: 4866963500.0\n",
      "Image saved as /content/output/output_at_iteration_1.png\n",
      "Iteration 1 completed in 5s\n",
      "Start of iteration 2\n",
      "Current loss value: 4190534700.0\n",
      "Image saved as /content/output/output_at_iteration_2.png\n",
      "Iteration 2 completed in 6s\n",
      "Start of iteration 3\n",
      "Current loss value: 3874594300.0\n",
      "Image saved as /content/output/output_at_iteration_3.png\n",
      "Iteration 3 completed in 6s\n",
      "Start of iteration 4\n",
      "Current loss value: 3665689300.0\n",
      "Image saved as /content/output/output_at_iteration_4.png\n",
      "Iteration 4 completed in 6s\n",
      "Start of iteration 5\n",
      "Current loss value: 3522369000.0\n",
      "Image saved as /content/output/output_at_iteration_5.png\n",
      "Iteration 5 completed in 6s\n",
      "Start of iteration 6\n",
      "Current loss value: 3414872300.0\n",
      "Image saved as /content/output/output_at_iteration_6.png\n",
      "Iteration 6 completed in 6s\n",
      "Start of iteration 7\n",
      "Current loss value: 3329066000.0\n",
      "Image saved as /content/output/output_at_iteration_7.png\n",
      "Iteration 7 completed in 6s\n",
      "Start of iteration 8\n",
      "Current loss value: 3264152600.0\n",
      "Image saved as /content/output/output_at_iteration_8.png\n",
      "Iteration 8 completed in 6s\n",
      "Start of iteration 9\n",
      "Current loss value: 3211668500.0\n",
      "Image saved as /content/output/output_at_iteration_9.png\n",
      "Iteration 9 completed in 6s\n",
      "Start of iteration 10\n",
      "Current loss value: 3166680000.0\n",
      "Image saved as /content/output/output_at_iteration_10.png\n",
      "Iteration 10 completed in 6s\n",
      "Start of iteration 11\n",
      "Current loss value: 3128992300.0\n",
      "Image saved as /content/output/output_at_iteration_11.png\n",
      "Iteration 11 completed in 6s\n",
      "Start of iteration 12\n",
      "Current loss value: 3096074000.0\n",
      "Image saved as /content/output/output_at_iteration_12.png\n",
      "Iteration 12 completed in 6s\n",
      "Start of iteration 13\n",
      "Current loss value: 3067837700.0\n",
      "Image saved as /content/output/output_at_iteration_13.png\n",
      "Iteration 13 completed in 6s\n",
      "Start of iteration 14\n",
      "Current loss value: 3043668500.0\n",
      "Image saved as /content/output/output_at_iteration_14.png\n",
      "Iteration 14 completed in 6s\n",
      "Start of iteration 15\n",
      "Current loss value: 3022976000.0\n",
      "Image saved as /content/output/output_at_iteration_15.png\n",
      "Iteration 15 completed in 6s\n",
      "Start of iteration 16\n",
      "Current loss value: 3004553000.0\n",
      "Image saved as /content/output/output_at_iteration_16.png\n",
      "Iteration 16 completed in 6s\n",
      "Start of iteration 17\n",
      "Current loss value: 2987697700.0\n",
      "Image saved as /content/output/output_at_iteration_17.png\n",
      "Iteration 17 completed in 6s\n",
      "Start of iteration 18\n",
      "Current loss value: 2972799700.0\n",
      "Image saved as /content/output/output_at_iteration_18.png\n",
      "Iteration 18 completed in 6s\n",
      "Start of iteration 19\n",
      "Current loss value: 2959672300.0\n",
      "Image saved as /content/output/output_at_iteration_19.png\n",
      "Iteration 19 completed in 6s\n",
      "Start of iteration 20\n",
      "Current loss value: 2947673300.0\n",
      "Image saved as /content/output/output_at_iteration_20.png\n",
      "Iteration 20 completed in 6s\n",
      "Start of iteration 21\n",
      "Current loss value: 2936751600.0\n",
      "Image saved as /content/output/output_at_iteration_21.png\n",
      "Iteration 21 completed in 6s\n",
      "Start of iteration 22\n",
      "Current loss value: 2926917000.0\n",
      "Image saved as /content/output/output_at_iteration_22.png\n",
      "Iteration 22 completed in 6s\n",
      "Start of iteration 23\n",
      "Current loss value: 2918497000.0\n",
      "Image saved as /content/output/output_at_iteration_23.png\n",
      "Iteration 23 completed in 6s\n",
      "Start of iteration 24\n",
      "Current loss value: 2910576600.0\n",
      "Image saved as /content/output/output_at_iteration_24.png\n",
      "Iteration 24 completed in 6s\n",
      "Start of iteration 25\n",
      "Current loss value: 2903606800.0\n",
      "Image saved as /content/output/output_at_iteration_25.png\n",
      "Iteration 25 completed in 6s\n",
      "Start of iteration 26\n",
      "Current loss value: 2896808000.0\n",
      "Image saved as /content/output/output_at_iteration_26.png\n",
      "Iteration 26 completed in 6s\n",
      "Start of iteration 27\n",
      "Current loss value: 2890445000.0\n",
      "Image saved as /content/output/output_at_iteration_27.png\n",
      "Iteration 27 completed in 6s\n",
      "Start of iteration 28\n",
      "Current loss value: 2884663800.0\n",
      "Image saved as /content/output/output_at_iteration_28.png\n",
      "Iteration 28 completed in 6s\n",
      "Start of iteration 29\n",
      "Current loss value: 2879510000.0\n",
      "Image saved as /content/output/output_at_iteration_29.png\n",
      "Iteration 29 completed in 6s\n",
      "Start of iteration 30\n",
      "Current loss value: 2874808300.0\n",
      "Image saved as /content/output/output_at_iteration_30.png\n",
      "Iteration 30 completed in 6s\n",
      "Start of iteration 31\n",
      "Current loss value: 2870524400.0\n",
      "Image saved as /content/output/output_at_iteration_31.png\n",
      "Iteration 31 completed in 6s\n",
      "Start of iteration 32\n",
      "Current loss value: 2866595000.0\n",
      "Image saved as /content/output/output_at_iteration_32.png\n",
      "Iteration 32 completed in 6s\n",
      "Start of iteration 33\n",
      "Current loss value: 2863071700.0\n",
      "Image saved as /content/output/output_at_iteration_33.png\n",
      "Iteration 33 completed in 6s\n",
      "Start of iteration 34\n",
      "Current loss value: 2859839500.0\n",
      "Image saved as /content/output/output_at_iteration_34.png\n",
      "Iteration 34 completed in 6s\n",
      "Start of iteration 35\n",
      "Current loss value: 2856909300.0\n",
      "Image saved as /content/output/output_at_iteration_35.png\n",
      "Iteration 35 completed in 6s\n",
      "Start of iteration 36\n",
      "Current loss value: 2854245600.0\n",
      "Image saved as /content/output/output_at_iteration_36.png\n",
      "Iteration 36 completed in 6s\n",
      "Start of iteration 37\n",
      "Current loss value: 2851760000.0\n",
      "Image saved as /content/output/output_at_iteration_37.png\n",
      "Iteration 37 completed in 6s\n",
      "Start of iteration 38\n",
      "Current loss value: 2849482500.0\n",
      "Image saved as /content/output/output_at_iteration_38.png\n",
      "Iteration 38 completed in 6s\n",
      "Start of iteration 39\n",
      "Current loss value: 2847403000.0\n",
      "Image saved as /content/output/output_at_iteration_39.png\n",
      "Iteration 39 completed in 6s\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "# Aplica el optimizador (L-BFGS) de scipy-based sobre los pixels de la imagen generada \n",
    "# para minimizar la funcion de perdida de la red neuronal correspondiente al estilo.\n",
    "\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # Graba las imagenes generadas\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Siw_fzXkyXWs",
    "outputId": "b647e0ff-339b-425e-b189-1adc8ec579f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/Resultado_Loss_stylw_1_contw_10_TotVar_0.9.zip'"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "archivo_salida = 'Resultado' + NombreSalida\n",
    "shutil.make_archive(archivo_salida, 'zip', '/content/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nt0q7Wi20e0d"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "download_zip = '/content/'+ archivo_salida + '.zip'\n",
    "files.download(download_zip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2kfuqfZPUjQ"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "*Respuesta:* \n",
    "\n",
    "<font color=\"003300\"><b>\n",
    "*A continuación se exponen las imagenes que se originaron secuencialmente durante el entrenamiento, puede apreciarse como lentamente van absorbiendo la transferencia de estilo.*\n",
    "</b></font>\n",
    "    \n",
    "    \n",
    "| Parametros: style_weight = 10, content_weight, = 1 total_variation_weight = 0.9 | Parametros: style_weight = 10, content_weight, = 1 total_variation_weight = 0.0        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Resultado_Loss_stylw_10_contw_1_TotVar_0.9_.gif\">| <img src=\"image/Resultado_Loss_stylw_10_contw_1_TotVar_0.0_.gif\">\n",
    "\n",
    "\n",
    "\n",
    "| Parametros: style_weight = 1, content_weight, = 10 total_variation_weight = 0.0 | Parametros: style_weight = 1, content_weight, = 10 total_variation_weight = 0.9        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Resultado_Loss_stylw_1_contw_10_TotVar_0.0_.gif\">| <img src=\"image/Resultado_Loss_stylw_1_contw_10_TotVar_0.9_.gif\">\n",
    "\n",
    "\n",
    "\n",
    "| Parametros: style_weight = 5, content_weight, = 5 total_variation_weight = 0.0 | Parametros: style_weight = 5, content_weight, = 5 total_variation_weight = 0.9        \n",
    "|:-: | :-:\n",
    "| <img src=\"image/Resultado_Loss_stylw_5_contw_5_TotVar_0.0_.gif\">| <img src=\"image/Resultado_Loss_stylw_5_contw_5_TotVar_0.9_.gif\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "*Respuesta:* \n",
    "\n",
    "<font color=\"003300\"><b>\n",
    "**El resultado obtenido del entrenamiento fue compilado en archivo gif animado con el proposito de visulizar los cambios en la imagen durante el entrenamiento.**\n",
    "</b></font>\n",
    "\n",
    "| Parametros: style_weight = 70, content_weight, = 30 total_variation_weight = 4 |\n",
    "|:-: |\n",
    "| <img src=\"image/Resultado2_Loss_stylw_70_contw_30_TotVar_4.gif\">|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4po7Ce2I9sP"
   },
   "outputs": [],
   "source": [
    "\"\"\"!rm /content/output/output_at_iteration_0.png\n",
    "!rm /content/output/output_at_iteration_1.png\n",
    "!rm /content/output/output_at_iteration_2.png\n",
    "!rm /content/output/output_at_iteration_3.png\n",
    "!rm /content/output/output_at_iteration_4.png\n",
    "!rm /content/output/output_at_iteration_5.png\n",
    "!rm /content/output/output_at_iteration_6.png\n",
    "!rm /content/output/output_at_iteration_7.png\n",
    "!rm /content/output/output_at_iteration_8.png\n",
    "!rm /content/output/output_at_iteration_9.png\n",
    "!rm /content/output/output_at_iteration_10.png\n",
    "!rm /content/output/output_at_iteration_11.png\n",
    "!rm /content/output/output_at_iteration_12.png\n",
    "!rm /content/output/output_at_iteration_13.png\n",
    "!rm /content/output/output_at_iteration_14.png\n",
    "!rm /content/output/output_at_iteration_15.png\n",
    "!rm /content/output/output_at_iteration_16.png\n",
    "!rm /content/output/output_at_iteration_17.png\n",
    "!rm /content/output/output_at_iteration_18.png\n",
    "!rm /content/output/output_at_iteration_19.png\n",
    "!rm /content/output/output_at_iteration_20.png\n",
    "!rm /content/output/output_at_iteration_21.png\n",
    "!rm /content/output/output_at_iteration_22.png\n",
    "!rm /content/output/output_at_iteration_23.png\n",
    "!rm /content/output/output_at_iteration_24.png\n",
    "!rm /content/output/output_at_iteration_25.png\n",
    "!rm /content/output/output_at_iteration_26.png\n",
    "!rm /content/output/output_at_iteration_27.png\n",
    "!rm /content/output/output_at_iteration_28.png\n",
    "!rm /content/output/output_at_iteration_29.png\n",
    "!rm /content/output/output_at_iteration_30.png\n",
    "!rm /content/output/output_at_iteration_31.png\n",
    "!rm /content/output/output_at_iteration_32.png\n",
    "!rm /content/output/output_at_iteration_33.png\n",
    "!rm /content/output/output_at_iteration_34.png\n",
    "!rm /content/output/output_at_iteration_35.png\n",
    "!rm /content/output/output_at_iteration_36.png\n",
    "!rm /content/output/output_at_iteration_37.png\n",
    "!rm /content/output/output_at_iteration_38.png\n",
    "!rm /content/output/output_at_iteration_39.png\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uSN0zFcFJed3",
    "outputId": "a764b7b5-10ac-411b-de50-ef1bcac18096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(1,40,1):\\n  filetodelete = '/content/output/output_at_iteration_'+str(i)+'.png'\\n  #!rm [filetodelete]\\n  print(filetodelete)\""
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in range(1,40,1):\n",
    "  filetodelete = '/content/output/output_at_iteration_'+str(i)+'.png'\n",
    "  #!rm [filetodelete]\n",
    "  print(filetodelete)\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cambio Características Trabajo Final CNN - Style Transfer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
